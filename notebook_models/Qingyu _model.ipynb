{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports and Extra Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import random\n",
    "from datetime import datetime\n",
    "from datetime import timedelta\n",
    "%load_ext line_profiler\n",
    "sns.set(style=\"darkgrid\")\n",
    "import requests\n",
    "import pprint\n",
    "import re\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Qingyu\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:2785: DtypeWarning: Columns (77,84,104,105,106,108,110,112,114,115,116,118,120) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time cost:  0:00:35.276494\n"
     ]
    }
   ],
   "source": [
    "time1 = datetime.now()\n",
    "filename = '../cleaned_flight_data_updated.csv'\n",
    "random.seed(234)\n",
    "p = 0.05  # p% of lines\n",
    "df = pd.read_csv(\n",
    "         filename,\n",
    "         header=0, \n",
    "         parse_dates = ['FL_DATE','dep_datetime','arr_datetime'],\n",
    "         skiprows=lambda i: i>0 and random.random() > p\n",
    ")\n",
    "time2 = datetime.now()\n",
    "print('Time cost: ', time2-time1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if DEP_DELAY is NaN, drop because useless for our model\n",
    "df = df.dropna(subset=['DEP_DELAY'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visibility/Wind Speed Cleaning and Imputing NaN values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time cost:  0:00:03.383933\n"
     ]
    }
   ],
   "source": [
    "# visibility column cleaning\n",
    "time1 = datetime.now()\n",
    "\n",
    "import math\n",
    "def spacetonan(x):\n",
    "    if isinstance(x, str) and x != '':\n",
    "        return float(x)\n",
    "    elif x == '':\n",
    "        return np.nan\n",
    "    return x\n",
    "\n",
    "# remove 'V', 'Vs', 's', etc.\n",
    "df['HOURLYVISIBILITY_origin'] = df['HOURLYVISIBILITY_origin'].str.replace('[^\\d(.)]', \"\")\n",
    "df['HOURLYVISIBILITY_dest'] = df['HOURLYVISIBILITY_dest'].str.replace('[^\\d(.)]', \"\")\n",
    "df['HOURLYWindSpeed_origin'] = df['HOURLYWindSpeed_origin'].str.replace('[^\\d(.)]', \"\")\n",
    "df['HOURLYWindSpeed_dest'] = df['HOURLYWindSpeed_dest'].str.replace('[^\\d(.)]', \"\")\n",
    "\n",
    "# for the entries with space, fill with nan\n",
    "df['HOURLYVISIBILITY_origin'] = list(map(spacetonan, df['HOURLYVISIBILITY_origin']))\n",
    "df['HOURLYVISIBILITY_dest'] = list(map(spacetonan, df['HOURLYVISIBILITY_dest']))\n",
    "df['HOURLYWindSpeed_origin'] = list(map(spacetonan, df['HOURLYWindSpeed_origin']))\n",
    "df['HOURLYWindSpeed_dest'] = list(map(spacetonan, df['HOURLYWindSpeed_dest']))\n",
    "\n",
    "# impute the nan values to mean (~9.4 mi visibility)\n",
    "np.set_printoptions(threshold=np.nan)\n",
    "from sklearn.impute import SimpleImputer\n",
    "imp_mean = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "df['HOURLYVISIBILITY_origin_imp'] = imp_mean.fit_transform(df[['HOURLYVISIBILITY_origin']]).ravel()\n",
    "df['HOURLYVISIBILITY_dest_imp'] = imp_mean.fit_transform(df[['HOURLYVISIBILITY_dest']]).ravel()\n",
    "df['HOURLYWindSpeed_origin_imp'] = imp_mean.fit_transform(df[['HOURLYWindSpeed_origin']]).ravel()\n",
    "df['HOURLYWindSpeed_dest_imp'] = imp_mean.fit_transform(df[['HOURLYWindSpeed_dest']]).ravel()\n",
    "\n",
    "time2 = datetime.now()\n",
    "print('Time cost: ', time2-time1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parsing \"present weather type\" and adding column with most salient weather code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# given an entry in the HOURLYPRSENTWEATHERTYPE, give AW xx value\n",
    "# otherwise return 0\n",
    "def regex_weather_cond(h_pres_w):\n",
    "    pattern = re.compile(r'\\d{2}')\n",
    "    if isinstance(h_pres_w, str):\n",
    "        if re.search(r'\\|.*?(([A-Za-z]{2,}:(\\d{2})\\s)*)\\|', h_pres_w):\n",
    "            string = re.search(r'\\|.*?(([A-Za-z]{2,}:(\\d{2})\\s)*)\\|', h_pres_w).group(0)\n",
    "            match = pattern.findall(string)\n",
    "        else:\n",
    "            return 0\n",
    "    else:\n",
    "        return 0\n",
    "    return most_severe_cond(match)\n",
    "\n",
    "# hard code severe weather condition\n",
    "# based mostly on avg delay min per weather type\n",
    "# smoke from Oct 2017 CA forestfire is high cancelled but not delay\n",
    "def most_severe_cond(lst):\n",
    "    # freezing rain\n",
    "    if '64' in lst:\n",
    "        return 64\n",
    "    elif '65' in lst:\n",
    "        return 65\n",
    "    elif '66' in lst:\n",
    "        return 66\n",
    "    # ice pellets\n",
    "    elif '74' in lst:\n",
    "        return 74\n",
    "    elif '75' in lst:\n",
    "        return 75\n",
    "    elif '76' in lst:\n",
    "        return 76\n",
    "    # thunderstorm with hail\n",
    "    elif '93' in lst:\n",
    "        return 93\n",
    "    # snow\n",
    "    elif '71' in lst:\n",
    "        return 71\n",
    "    elif '72' in lst:\n",
    "        return 72\n",
    "    elif '73' in lst:\n",
    "        return 73\n",
    "    # fog\n",
    "    elif '30' in lst:\n",
    "        return 30\n",
    "    elif '31' in lst:\n",
    "        return 31\n",
    "    elif '32' in lst:\n",
    "        return 32\n",
    "    elif '33' in lst:\n",
    "        return 33\n",
    "    elif '34' in lst:\n",
    "        return 34\n",
    "    # safety return 0 if somehow pass empty list\n",
    "    elif len(lst) == 0:\n",
    "        return 0\n",
    "    # return max element as int from list of strings\n",
    "    # after those preceding cases, most severe is higher code\n",
    "    # also not too many cases of combination of drastically different codes \n",
    "    else:\n",
    "        return max(list(map(int, lst)))\n",
    "    \n",
    "\n",
    "# hard code severe weather condition\n",
    "# based mostly on avg delay min per weather type\n",
    "# smoke from Oct 2017 CA forestfire is high cancelled but not delay\n",
    "def ordinal_ordering(x):\n",
    "    # freezing rain\n",
    "    if x == 64:\n",
    "        return 115\n",
    "    elif x == 65:\n",
    "        return 116\n",
    "    elif x == 66:\n",
    "        return 117\n",
    "    # ice pellets\n",
    "    elif x == 74:\n",
    "        return 112\n",
    "    elif x == 75:\n",
    "        return 113\n",
    "    elif x == 76:\n",
    "        return 114\n",
    "    # thunderstorm with hail\n",
    "    elif x == 93:\n",
    "        return 113\n",
    "    # snow\n",
    "    elif x == 71:\n",
    "        return 110\n",
    "    elif x == 72:\n",
    "        return 111\n",
    "    elif x == 73:\n",
    "        return 112\n",
    "    # fog\n",
    "    elif x == 30:\n",
    "        return 105\n",
    "    elif x == 31:\n",
    "        return 106\n",
    "    elif x == 32:\n",
    "        return 107\n",
    "    elif x == 33:\n",
    "        return 108\n",
    "    elif x == 34:\n",
    "        return 109\n",
    "    else:\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time cost:  0:00:01.428189\n"
     ]
    }
   ],
   "source": [
    "# make the present weather type columns into new col\n",
    "# with most severe weather code selected as integer\n",
    "time1 = datetime.now()\n",
    "df['origin_sev_code'] = df['HOURLYPRSENTWEATHERTYPE_origin'].apply(\n",
    "    lambda x: regex_weather_cond(x))\n",
    "df['dest_sev_code'] = df['HOURLYPRSENTWEATHERTYPE_dest'].apply(\n",
    "    lambda x: regex_weather_cond(x))\n",
    "\n",
    "df['origin_enc_code'] = df['origin_sev_code'].apply(\n",
    "    lambda x: ordinal_ordering(x))\n",
    "df['dest_enc_code'] = df['dest_sev_code'].apply(\n",
    "    lambda x: ordinal_ordering(x))\n",
    "time2 = datetime.now()\n",
    "print('Time cost: ', time2-time1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0 91 61 71  5 62 51 63 31 35 72 30 90 92 73 64 67 95 93 33 54 52 75 74\n",
      " 81  4 68 65 18 82 99 85 96 89]\n",
      "[ 0 61 31 92 71 95 51  5 30 62 91 90 63 72 54 35 64 67 73 75 68 74 33 89\n",
      "  4 18 65 52 93 99 81 55 86]\n",
      "[  0  91  61 110   5  62  51  63 106  35 111 105  90  92 112 115  67  95\n",
      " 113 108  54  52  81   4  68 116  18  82  99  85  96  89]\n",
      "[  0  61 106  92 110  95  51   5 105  62  91  90  63 111  54  35 115  67\n",
      " 112 113  68 108  89   4  18 116  52  99  81  55  86]\n"
     ]
    }
   ],
   "source": [
    "print(df.origin_sev_code.unique())\n",
    "print(df.dest_sev_code.unique())\n",
    "print(df.origin_enc_code.unique())\n",
    "print(df.dest_enc_code.unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Binary Classification\n",
    "\n",
    "Using \"DEP_DEL15\":\n",
    "- 1 means delay >= 15\n",
    "- 0 means delay < 15 (on-time / early)\n",
    "\n",
    "Goal is to predict this classification. We will use **F1-score** as the primary evaluation metric, since we are concerned with both classes of classificacation: on-time/early vs. delayed. Since the classes are unbalanced, metrics such as accuracy will give a baseline model where we classify all flights as on-time very well (which is misleading since that would not be a useful model). \n",
    "\n",
    "Let's start with a **random forest** weather model, where we predict the DEP_DEL15 using the features:\n",
    "- weather code - origin\n",
    "- visibilty - origin\n",
    "- wind speed at origin\n",
    "- precipitation at origin\n",
    "- (possibly temperature)\n",
    "\n",
    "After weather, we will use flight/airport data:\n",
    "- number of seats\n",
    "- departure airport (*need encoding/merging - use passenger count*)\n",
    "- carrier (*need ordinal encoding*)\n",
    "- departure time (DEP_TIME)\n",
    "- duration of flight\n",
    "\n",
    "Later on if we have time:\n",
    "- cloud cover (need complicated regex)\n",
    "- time dependence/delay\n",
    "- other things\n",
    "\n",
    "http://scikit-learn.org/stable/auto_examples/ensemble/plot_feature_transformation.html#sphx-glr-auto-examples-ensemble-plot-feature-transformation-py\n",
    "\n",
    "http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html#sklearn.ensemble.RandomForestClassifier\n",
    "\n",
    "https://roamanalytics.com/2016/10/28/are-categorical-variables-getting-lost-in-your-random-forests/\n",
    "\n",
    "http://docs.h2o.ai/h2o/latest-stable/h2o-docs/data-science/drf.html\n",
    "\n",
    "https://en.wikipedia.org/wiki/Receiver_operating_characteristic\n",
    "\n",
    "http://scikit-learn.org/stable/modules/model_evaluation.html\n",
    "\n",
    "http://scikit-learn.org/stable/auto_examples/classification/plot_classifier_comparison.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import all these lol\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.datasets import make_moons, make_circles, make_classification\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import log10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['log_origin_passenger_count'] = df['origin_passenger_count'].apply(lambda x: log10(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_column_list = ['DEP_TIME', 'number_of_seats', 'log_origin_passenger_count']\n",
    "X_column_list = ['DEP_TIME', 'number_of_seats', 'origin_enc_code']\n",
    "\n",
    "X = df[X_column_list]\n",
    "y = df['DEP_DEL15']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0., 1.]), array([4884, 1718], dtype=int64))"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(y_pred, return_counts=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# predict all zeros baseline model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_0 = X_test.apply(lambda x: 0, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.balanced_accuracy_score(y_test, y_pred_0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# severe weather-delay baseline model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.07042253521126761\n",
      "0.8217019360648357\n",
      "0.50877762852249\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.84      0.98      0.90      1853\n",
      "         1.0       0.26      0.04      0.07       368\n",
      "\n",
      "   micro avg       0.82      0.82      0.82      2221\n",
      "   macro avg       0.55      0.51      0.49      2221\n",
      "weighted avg       0.74      0.82      0.76      2221\n",
      "\n",
      "[[1810   43]\n",
      " [ 353   15]]\n",
      "Time cost:  0:00:05.210361\n"
     ]
    }
   ],
   "source": [
    "time1 = datetime.now()\n",
    "clf = svm.SVC(kernel='rbf', gamma='auto')\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "print(metrics.f1_score(y_test, y_pred))\n",
    "print(clf.score(X_test, y_test))\n",
    "print(metrics.balanced_accuracy_score(y_test, y_pred))\n",
    "print(metrics.classification_report(y_test, y_pred))\n",
    "print(metrics.confusion_matrix(y_test, y_pred))\n",
    "time2 = datetime.now()\n",
    "print('Time cost: ', time2-time1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)\n",
    "sm = SMOTE(random_state=12, ratio = 1.0)\n",
    "X_train_res, y_train_res = sm.fit_sample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.259904912836767\n",
      "0.71968787515006\n",
      "0.5503492857887603\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.85      0.80      0.83      2780\n",
      "         1.0       0.23      0.30      0.26       552\n",
      "\n",
      "   micro avg       0.72      0.72      0.72      3332\n",
      "   macro avg       0.54      0.55      0.54      3332\n",
      "weighted avg       0.75      0.72      0.73      3332\n",
      "\n",
      "[[2234  546]\n",
      " [ 388  164]]\n",
      "Time cost:  0:00:20.979911\n"
     ]
    }
   ],
   "source": [
    "time1 = datetime.now()\n",
    "svc_clf = svm.SVC(kernel='rbf', gamma='auto')\n",
    "svc_clf.fit(X_train_res, y_train_res)\n",
    "y_pred = svc_clf.predict(X_test)\n",
    "print(metrics.f1_score(y_test, y_pred))\n",
    "print(svc_clf.score(X_test, y_test))\n",
    "print(metrics.balanced_accuracy_score(y_test, y_pred))\n",
    "print(metrics.classification_report(y_test, y_pred))\n",
    "print(metrics.confusion_matrix(y_test, y_pred))\n",
    "time2 = datetime.now()\n",
    "print('Time cost: ', time2-time1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2564885496183206\n",
      "0.71968787515006\n",
      "0.5460588051298092\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.85      0.79      0.82      2780\n",
      "         1.0       0.22      0.30      0.26       552\n",
      "\n",
      "   micro avg       0.71      0.71      0.71      3332\n",
      "   macro avg       0.54      0.55      0.54      3332\n",
      "weighted avg       0.75      0.71      0.73      3332\n",
      "\n",
      "[[2190  590]\n",
      " [ 384  168]]\n"
     ]
    }
   ],
   "source": [
    "X_test = X_test.reset_index(drop=True)\n",
    "\n",
    "for i in range(X_test.shape[0]):\n",
    "    if X_test.loc[i, 'origin_enc_code'] > 100:\n",
    "        y_pred[i] = 1\n",
    "print(metrics.f1_score(y_test, y_pred))\n",
    "print(svc_clf.score(X_test, y_test))\n",
    "print(metrics.balanced_accuracy_score(y_test, y_pred))\n",
    "print(metrics.classification_report(y_test, y_pred))\n",
    "print(metrics.confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SGD Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['log_origin_passenger_count'] = df['origin_passenger_count'].apply(lambda x: log10(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_column_list = ['DEP_TIME', 'number_of_seats']\n",
    "# X_column_list = ['DEP_TIME', 'number_of_seats', 'log_origin_passenger_count']\n",
    "X_column_list = ['DEP_TIME', 'number_of_seats', 'log_origin_passenger_count', 'origin_enc_code']\n",
    "\n",
    "X = df[X_column_list]\n",
    "y = df['DEP_DEL15']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)\n",
    "sm = SMOTE(random_state=0, ratio = 1)\n",
    "X_train_res, y_train_res = sm.fit_sample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best [rs, score] = [92, 0.615126], mean score =  0.5252418550190736\n",
      "Time cost:  0:00:07.378238\n"
     ]
    }
   ],
   "source": [
    "time1 = datetime.now()\n",
    "scores = []\n",
    "for rs in range(1,100):\n",
    "    sgd_clf = SGDClassifier(loss=\"hinge\", penalty=\"l2\", max_iter=5, random_state=rs, shuffle=True)\n",
    "    # \n",
    "    sgd_clf.fit(X_train_res, y_train_res)\n",
    "    y_pred = sgd_clf.predict(X_test)\n",
    "    scores.append(metrics.balanced_accuracy_score(y_test, y_pred))\n",
    "scores = np.array(scores)\n",
    "i = np.argmax(scores)\n",
    "print('best [rs, score] = [%g, %g], mean score = '%(i+1, scores[i]), scores.mean())\n",
    "time2 = datetime.now()\n",
    "print('Time cost: ', time2-time1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5556022956040985\n",
      "0.6151262694584592\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.89      0.52      0.66     27429\n",
      "         1.0       0.24      0.71      0.36      5852\n",
      "\n",
      "   micro avg       0.56      0.56      0.56     33281\n",
      "   macro avg       0.57      0.62      0.51     33281\n",
      "weighted avg       0.78      0.56      0.61     33281\n",
      "\n",
      "[[14354 13075]\n",
      " [ 1715  4137]]\n"
     ]
    }
   ],
   "source": [
    "sgd_clf = SGDClassifier(loss=\"hinge\", penalty=\"l2\", max_iter=5, shuffle=True, random_state=92)\n",
    "# \n",
    "sgd_clf.fit(X_train_res, y_train_res)\n",
    "y_pred = sgd_clf.predict(X_test)\n",
    "print(sgd_clf.score(X_test, y_test))\n",
    "print(metrics.balanced_accuracy_score(y_test, y_pred))\n",
    "print(metrics.classification_report(y_test, y_pred))\n",
    "print(metrics.confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0., 1.]), array([63939, 63939], dtype=int64))"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(y_train_res, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2002343679576936\n",
      "0.5034430252248601\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.85      0.04      0.07     27429\n",
      "         1.0       0.18      0.97      0.30      5852\n",
      "\n",
      "   micro avg       0.20      0.20      0.20     33281\n",
      "   macro avg       0.51      0.50      0.18     33281\n",
      "weighted avg       0.73      0.20      0.11     33281\n",
      "\n",
      "[[  981 26448]\n",
      " [  169  5683]]\n"
     ]
    }
   ],
   "source": [
    "print(sgd_clf.score(X_test, y_test))\n",
    "print(metrics.balanced_accuracy_score(y_test, y_pred))\n",
    "print(metrics.classification_report(y_test, y_pred))\n",
    "print(metrics.confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5602179051433808\n",
      "{'loss': 'modified_huber', 'penalty': 'elasticnet'}\n"
     ]
    }
   ],
   "source": [
    "losses = ['hinge', 'log', 'modified_huber', 'squared_hinge', 'perceptron']\n",
    "penalties = ['none', 'l2', 'l1', 'elasticnet']\n",
    "nfolds = 5\n",
    "param_grid = {'loss': losses, 'penalty': penalties}\n",
    "grid_search = GridSearchCV(SGDClassifier(max_iter=5), param_grid, cv=nfolds, scoring='balanced_accuracy')\n",
    "grid_search.fit(X, y)\n",
    "print(grid_search.best_score_)\n",
    "print(grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8236558496883455\n",
      "0.5029162268947719\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.82      1.00      0.90    275556\n",
      "         1.0       0.48      0.01      0.01     58949\n",
      "\n",
      "   micro avg       0.82      0.82      0.82    334505\n",
      "   macro avg       0.65      0.50      0.46    334505\n",
      "weighted avg       0.76      0.82      0.75    334505\n",
      "\n",
      "[[275069    487]\n",
      " [ 58501    448]]\n"
     ]
    }
   ],
   "source": [
    "sgd_clf = SGDClassifier(loss=\"modified_huber\", penalty=\"elasticnet\", max_iter=5, shuffle=True)\n",
    "# \n",
    "sgd_clf.fit(X_train_res, y_train_res)\n",
    "y_pred = sgd_clf.predict(X_test)\n",
    "print(sgd_clf.score(X_test, y_test))\n",
    "print(metrics.balanced_accuracy_score(y_test, y_pred))\n",
    "print(metrics.classification_report(y_test, y_pred))\n",
    "print(metrics.confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['log_origin_passenger_count'] = df['origin_passenger_count'].apply(lambda x: log10(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_column_list = ['DEP_TIME']\n",
    "# X_column_list = ['DEP_TIME', 'number_of_seats']\n",
    "X_column_list = ['DEP_TIME', 'number_of_seats', 'origin_passenger_count', 'HOURLYVISIBILITY_origin_imp', 'HOURLYWindSpeed_origin_imp', 'origin_enc_code']\n",
    "# X_column_list = ['DEP_TIME', 'number_of_seats', 'origin_enc_code']\n",
    "\n",
    "X = df[X_column_list]\n",
    "y = df['DEP_DEL15']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)\n",
    "sm = SMOTE(random_state=0, ratio = 1)\n",
    "X_train_res, y_train_res = sm.fit_sample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.46032291 0.06244019 0.01238502 0.26505699 0.08096094 0.11883395]\n",
      "0.5254091867087188\n",
      "0.6222507895510884\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.91      0.47      0.62    275556\n",
      "         1.0       0.24      0.77      0.36     58949\n",
      "\n",
      "   micro avg       0.53      0.53      0.53    334505\n",
      "   macro avg       0.57      0.62      0.49    334505\n",
      "weighted avg       0.79      0.53      0.58    334505\n",
      "\n",
      "[[130255 145301]\n",
      " [ 13452  45497]]\n"
     ]
    }
   ],
   "source": [
    "rf_clf = RandomForestClassifier(n_estimators=100, max_depth=2, random_state=0)\n",
    "rf_clf.fit(X_train_res, y_train_res)\n",
    "y_pred = rf_clf.predict(X_test)\n",
    "print(rf_clf.feature_importances_)\n",
    "print(rf_clf.score(X_test, y_test))\n",
    "print(metrics.balanced_accuracy_score(y_test, y_pred))\n",
    "print(metrics.classification_report(y_test, y_pred))\n",
    "print(metrics.confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.53285028 0.1830278  0.28412192]\n",
      "0.5435533788047234\n",
      "0.6082197597989086\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.89      0.51      0.65     27429\n",
      "         1.0       0.24      0.71      0.35      5852\n",
      "\n",
      "   micro avg       0.54      0.54      0.54     33281\n",
      "   macro avg       0.56      0.61      0.50     33281\n",
      "weighted avg       0.78      0.54      0.60     33281\n",
      "\n",
      "[[13947 13482]\n",
      " [ 1709  4143]]\n"
     ]
    }
   ],
   "source": [
    "rf_clf = RandomForestClassifier(n_estimators=100, max_depth=2, random_state=0)\n",
    "rf_clf.fit(X_train_res, y_train_res)\n",
    "y_pred = rf_clf.predict(X_test)\n",
    "print(rf_clf.feature_importances_)\n",
    "print(rf_clf.score(X_test, y_test))\n",
    "print(metrics.balanced_accuracy_score(y_test, y_pred))\n",
    "print(metrics.classification_report(y_test, y_pred))\n",
    "print(metrics.confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.]\n",
      "0.7931853009224482\n",
      "0.5670357379782767\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.85      0.92      0.88     27429\n",
      "         1.0       0.36      0.22      0.27      5852\n",
      "\n",
      "   micro avg       0.79      0.79      0.79     33281\n",
      "   macro avg       0.60      0.57      0.58     33281\n",
      "weighted avg       0.76      0.79      0.77     33281\n",
      "\n",
      "[[25121  2308]\n",
      " [ 4575  1277]]\n",
      "0.16462658872388428\n"
     ]
    }
   ],
   "source": [
    "rf_clf = RandomForestClassifier(n_estimators=100, max_depth=2, random_state=0)\n",
    "rf_clf.fit(X_train_res, y_train_res)\n",
    "y_pred = rf_clf.predict(X_test)\n",
    "print(rf_clf.feature_importances_)\n",
    "print(rf_clf.score(X_test, y_test))\n",
    "print(metrics.balanced_accuracy_score(y_test, y_pred))\n",
    "print(metrics.classification_report(y_test, y_pred))\n",
    "print(metrics.confusion_matrix(y_test, y_pred))\n",
    "print(metrics.matthews_corrcoef(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Qingyu\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:543: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  mcc = cov_ytyp / np.sqrt(cov_ytyt * cov_ypyp)\n",
      "C:\\Users\\Qingyu\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:543: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  mcc = cov_ytyp / np.sqrt(cov_ytyt * cov_ypyp)\n",
      "C:\\Users\\Qingyu\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:543: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  mcc = cov_ytyp / np.sqrt(cov_ytyt * cov_ypyp)\n",
      "C:\\Users\\Qingyu\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:543: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  mcc = cov_ytyp / np.sqrt(cov_ytyt * cov_ypyp)\n",
      "C:\\Users\\Qingyu\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:543: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  mcc = cov_ytyp / np.sqrt(cov_ytyt * cov_ypyp)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best [rs, score] = [10, 0.194164], mean score =  0.08665047249009492\n",
      "Time cost:  0:00:16.578904\n"
     ]
    }
   ],
   "source": [
    "time1 = datetime.now()\n",
    "scores = []\n",
    "for r in np.linspace(0.3,1,10):\n",
    "    sm = SMOTE(random_state=0, ratio = r)\n",
    "    X_train_res, y_train_res = sm.fit_sample(X_train, y_train)\n",
    "    rf_clf = RandomForestClassifier(n_estimators=100, max_depth=2, random_state=0)\n",
    "    rf_clf.fit(X_train_res, y_train_res)\n",
    "    y_pred = rf_clf.predict(X_test)\n",
    "    scores.append(metrics.matthews_corrcoef(y_test, y_pred))\n",
    "scores = np.array(scores)\n",
    "i = np.argmax(scores)\n",
    "print('best [rs, score] = [%g, %g], mean score = '%(i+1, scores[i]), scores.mean())\n",
    "time2 = datetime.now()\n",
    "print('Time cost: ', time2-time1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.80592737 0.19407263]\n",
      "0.5409392746612182\n",
      "0.6268646569941204\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.91      0.49      0.64     27429\n",
      "         1.0       0.24      0.76      0.37      5852\n",
      "\n",
      "   micro avg       0.54      0.54      0.54     33281\n",
      "   macro avg       0.57      0.63      0.50     33281\n",
      "weighted avg       0.79      0.54      0.59     33281\n",
      "\n",
      "[[13559 13870]\n",
      " [ 1408  4444]]\n",
      "0.19416404318603186\n"
     ]
    }
   ],
   "source": [
    "sm = SMOTE(random_state=0, ratio = r)\n",
    "X_train_res, y_train_res = sm.fit_sample(X_train, y_train)\n",
    "rf_clf = RandomForestClassifier(n_estimators=100, max_depth=2, random_state=0, min_samples_leaf=1)\n",
    "rf_clf.fit(X_train_res, y_train_res)\n",
    "y_pred = rf_clf.predict(X_test)\n",
    "print(rf_clf.feature_importances_)\n",
    "print(rf_clf.score(X_test, y_test))\n",
    "print(metrics.balanced_accuracy_score(y_test, y_pred))\n",
    "print(metrics.classification_report(y_test, y_pred))\n",
    "print(metrics.confusion_matrix(y_test, y_pred))\n",
    "print(metrics.matthews_corrcoef(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5\n",
      "{'min_samples_leaf': 50}\n"
     ]
    }
   ],
   "source": [
    "min_samples_leaf = list(range(50,110,10))\n",
    "nfolds = 5\n",
    "param_grid = {'min_samples_leaf': min_samples_leaf}\n",
    "grid_search = GridSearchCV(RandomForestClassifier(n_estimators=100, max_depth=2, random_state=0), param_grid, cv=nfolds, scoring='balanced_accuracy')\n",
    "grid_search.fit(X, y)\n",
    "print(grid_search.best_score_)\n",
    "print(grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6186327362663987\n",
      "{'classification__min_samples_leaf': 10}\n",
      "Time cost:  0:02:40.593291\n"
     ]
    }
   ],
   "source": [
    "time1 = datetime.now()\n",
    "smote = SMOTE(random_state=0, ratio = 1)\n",
    "rf_clf = RandomForestClassifier(n_estimators=100, max_depth=2, random_state=0)\n",
    "\n",
    "model = Pipeline([\n",
    "        ('sampling', smote),\n",
    "        ('classification', rf_clf)\n",
    "    ])\n",
    "nfolds = 5\n",
    "min_samples_leaf = list(range(10,110,10))\n",
    "params = {'classification__min_samples_leaf': min_samples_leaf}\n",
    "grid = GridSearchCV(model, param_grid=params, cv=nfolds, scoring='balanced_accuracy')\n",
    "grid.fit(X, y)\n",
    "print(grid.best_score_)\n",
    "print(grid.best_params_)\n",
    "time2 = datetime.now()\n",
    "print('Time cost: ', time2-time1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Onehot encoder for carriers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['B6'],\n",
       " ['DL'],\n",
       " ['WN'],\n",
       " ['AA'],\n",
       " ['UA'],\n",
       " ['NK'],\n",
       " ['HA'],\n",
       " ['AS'],\n",
       " ['OO'],\n",
       " ['EV'],\n",
       " ['VX'],\n",
       " ['F9']]"
      ]
     },
     "execution_count": 368,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['OP_CARRIER'].unique().reshape(-1,1).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OneHotEncoder(categorical_features=None, categories=None,\n",
       "       dtype=<class 'numpy.float64'>, handle_unknown='ignore',\n",
       "       n_values=None, sparse=True)"
      ]
     },
     "execution_count": 369,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "onehot_enc = OneHotEncoder(handle_unknown='ignore')\n",
    "carrier_list = df['OP_CARRIER'].unique().reshape(-1,1).tolist()\n",
    "onehot_enc.fit(carrier_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['B6', 'DL', 'WN', 'WN', 'B6'], dtype=object)"
      ]
     },
     "execution_count": 377,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['OP_CARRIER'].head().values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "print(onehot_enc.transform(df['OP_CARRIER'].head().values.reshape(-1,1)).toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['log_origin_passenger_count'] = df['origin_passenger_count'].apply(lambda x: log10(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_column_list = ['DEP_TIME']\n",
    "# X_column_list = ['DEP_TIME', 'number_of_seats', 'OP_CARRIER']\n",
    "X_column_list = ['DEP_TIME', 'number_of_seats', 'OP_CARRIER', 'origin_passenger_count', 'HOURLYVISIBILITY_origin_imp', 'HOURLYWindSpeed_origin_imp', 'origin_enc_code']\n",
    "# X_column_list = ['DEP_TIME', 'number_of_seats', 'origin_enc_code']\n",
    "\n",
    "X = pd.get_dummies(df[X_column_list])\n",
    "y = df['DEP_DEL15']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)\n",
    "sm = SMOTE(random_state=0, ratio = 1)\n",
    "X_train_res, y_train_res = sm.fit_sample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time1 = datetime.now()\n",
    "rf_clf = RandomForestClassifier(n_estimators=100, max_depth=10, random_state=0)\n",
    "rf_clf.fit(X_train_res, y_train_res)\n",
    "y_pred = rf_clf.predict(X_test)\n",
    "print(rf_clf.feature_importances_)\n",
    "print(rf_clf.score(X_test, y_test))\n",
    "print(metrics.balanced_accuracy_score(y_test, y_pred))\n",
    "print(metrics.classification_report(y_test, y_pred))\n",
    "print(metrics.confusion_matrix(y_test, y_pred))\n",
    "print(metrics.matthews_corrcoef(y_test, y_pred))\n",
    "time2 = datetime.now()\n",
    "print('Time cost: ', time2-time1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# pipeline randomsearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time1 = datetime.now()\n",
    "smote = SMOTE(random_state=0, ratio = 1)\n",
    "rf_clf = RandomForestClassifier(n_estimators=100, max_depth=2, random_state=0)\n",
    "model = Pipeline([\n",
    "        ('sampling', smote),\n",
    "        ('classification', rf_clf)\n",
    "    ])\n",
    "nfolds = 3\n",
    "# Number of trees in random forest\n",
    "n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\n",
    "# Number of features to consider at every split\n",
    "max_features = ['auto', 'sqrt']\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
    "max_depth.append(None)\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [2, 5, 10]\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "# Method of selecting samples for training each tree\n",
    "bootstrap = [True, False]\n",
    "\n",
    "params_grid = {'classification__n_estimators': n_estimators,\n",
    "               'classification__max_features': max_features,\n",
    "               'classification__max_depth': max_depth,\n",
    "               'classification__min_samples_split': min_samples_split,\n",
    "               'classification__min_samples_leaf': min_samples_leaf,\n",
    "               'classification__bootstrap': bootstrap}\n",
    "\n",
    "randomized = RandomizedSearchCV(model, param_distributions=params_grid, n_iter = 100, cv=nfolds, scoring='balanced_accuracy')\n",
    "randomized.fit(X, y)\n",
    "print(randomized.best_score_)\n",
    "print(randomized.best_params_)\n",
    "time2 = datetime.now()\n",
    "print('Time cost: ', time2-time1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask.diagnostics import ProgressBar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with ProgressBar():"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
